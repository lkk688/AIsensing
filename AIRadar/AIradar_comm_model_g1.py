"""
Deep Learning Replacement for Radar CFAR + Comm Demapper

Features:
- Uses joint_dump.npy generated by your existing simulator.
- Multi-task model:
    * Radar: RD map -> detection heatmap (replaces CFAR).
    * Comm: OFDM equalized map -> symbol logits (replaces demapper).
- CNN + Token-Capped Self-Attention backbone for stable training without OOM.
- Modes:
    --mode train      : train + full evaluation + visualizations.
    --mode evaluate   : load checkpoint, evaluate on full dataset, save plots.
    --mode inference  : load checkpoint, run on a single sample, save plots.

Visualizations per sample:
- Radar: 2D RD map with GT, CFAR detections, DL detections.
- Radar: 3D RD map (uses AIRadarLib if available; otherwise Matplotlib 3D).
- Comm: Constellation (Tx, Rx, DL demap) + approximate eye diagram.
- Text summaries: Radar metrics + Comm BER/SER.
"""

import os
import math
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from scipy.ndimage import maximum_filter
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # noqa: F401

# Optional 3D visualization from your existing library
try:
    from AIRadarLib.visualization import plot_3d_range_doppler_map_with_ground_truth
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False

C = 3e8  # speed of light

# ----------------------------------------------------------------------
# Configs (TRADITIONAL modes only; OTFS skipped here)
# ----------------------------------------------------------------------
RADAR_COMM_CONFIGS = {
    'CN0566_TRADITIONAL': {
        'mode': 'TRADITIONAL',
        'fc': 10.25e9,
        'mod_order': 16,
        'radar_B': 500e6,
        'radar_T': 500e-6,
        'radar_fs': 2e6,
        'comm_B': 40e6,
        'comm_fs': 61.44e6,
        'comm_fft_size': 64,
        'comm_cp_len': 16,
        'channel_model': 'multipath',
        'R_max': 150.0,
        'num_rx': 1,
        'cfar_params': {
            'num_train': 12,
            'num_guard': 4,
            'threshold_offset': 15,
            'nms_kernel_size': 5
        }
    },

    'Automotive_77GHz_LongRange': {
        'mode': 'TRADITIONAL',
        'fc': 77e9,
        'mod_order': 4,
        'radar_B': 1.5e9,
        'radar_T': 40e-6,
        'radar_fs': 51.2e6,
        'comm_B': 400e6,
        'comm_fs': 512e6,
        'comm_fft_size': 1024,
        'comm_cp_len': 72,
        'channel_model': 'multipath',
        'R_max': 100.0,
        'num_rx': 1,
        'cfar_params': {
            'num_train': 10,
            'num_guard': 4,
            'threshold_offset': 15,
            'nms_kernel_size': 5
        }
    },

    'XBand_10GHz_MediumRange': {
        'mode': 'TRADITIONAL',
        'fc': 10e9,
        'mod_order': 16,
        'radar_B': 1.0e9,
        'radar_T': 160e-6,
        'radar_fs': 40e6,
        'comm_B': 40e6,
        'comm_fs': 40e6,
        'comm_fft_size': 64,
        'comm_cp_len': 16,
        'channel_model': 'multipath',
        'R_max': 100.0,
        'num_rx': 1,
        'cfar_params': {
            'num_train': 24,
            'num_guard': 8,
            'threshold_offset': 18,
            'nms_kernel_size': 7
        }
    },

    'AUTOMOTIVE_TRADITIONAL': {
        'mode': 'TRADITIONAL',
        'fc': 77e9,
        'mod_order': 64,
        'radar_B': 1.5e9,
        'radar_T': 60e-6,
        'radar_fs': 50e6,
        'comm_B': 400e6,
        'comm_fs': 512e6,
        'comm_fft_size': 1024,
        'comm_cp_len': 72,
        'channel_model': 'multipath',
        'R_max': 250.0,
        'num_rx': 4,
        'cfar_params': {
            'num_train': 16,
            'num_guard': 4,
            'threshold_offset': 15,
            'nms_kernel_size': 7
        }
    },
}

# ----------------------------------------------------------------------
# Dataset from joint_dump.npy
# ----------------------------------------------------------------------
class JointRadarCommDataset(Dataset):
    """
    Expects the same joint_dump.npy produced by your generator:
      each element: {
        'range_doppler_map': [D,R] (dB),
        'cfar_detections': list of dicts,
        'target_info': {'targets': [{'range','velocity','rcs'}, ...], 'snr_db': ...},
        'ofdm_map': [N_syms, N_fft] (dB),
        'comm_info': {
            'ber', 'tx_symbols', 'rx_symbols',
            'num_data_syms', 'fft_size', 'tx_ints', 'mod_order'
        }
      }
    """
    def __init__(self, npy_path, config_name, radar_sigma_cells=1.5):
        super().__init__()
        self.npy_path = npy_path
        self.config_name = config_name
        self.cfg = RADAR_COMM_CONFIGS[config_name]
        assert self.cfg['mode'] == 'TRADITIONAL', "This dataset loader is for TRADITIONAL mode only."

        self.samples = np.load(self.npy_path, allow_pickle=True)
        self.radar_sigma_cells = radar_sigma_cells

        self.fc = self.cfg['fc']
        self.lambda_c = C / self.fc
        self.radar_B = self.cfg['radar_B']
        self.radar_T = self.cfg['radar_T']

    def __len__(self):
        return len(self.samples)

    def _compute_axes(self, rdm):
        """Reconstruct range/velocity axes consistent with FMCW params."""
        D_r, R_r = rdm.shape
        # r_res = c / (2B)
        r_res = C / (2 * self.radar_B)
        # v_res = lambda / (2 * Nc * T_chirp)
        v_res = self.lambda_c / (2 * D_r * self.radar_T)
        r_axis = np.arange(R_r) * r_res
        v_axis = (np.arange(D_r) - D_r // 2) * v_res
        return r_axis, v_axis, r_res, v_res

    def _build_radar_label(self, rdm, targets):
        """Soft Gaussian heatmap labels centered at target cells."""
        D_r, R_r = rdm.shape
        label = np.zeros_like(rdm, dtype=np.float32)
        radius = 3
        sigma2 = self.radar_sigma_cells ** 2

        r_axis, v_axis, r_res, v_res = self._compute_axes(rdm)

        for t in targets:
            r_m = t['range']
            v_m = t['velocity']

            r_idx = int(round(r_m / r_res))
            v_idx = int(round(v_m / v_res) + D_r // 2)

            if not (0 <= r_idx < R_r and 0 <= v_idx < D_r):
                continue

            for dv in range(-radius, radius + 1):
                for dr in range(-radius, radius + 1):
                    rr = r_idx + dr
                    dd = v_idx + dv
                    if 0 <= rr < R_r and 0 <= dd < D_r:
                        dist2 = dr * dr + dv * dv
                        val = math.exp(-dist2 / (2 * sigma2))
                        label[dd, rr] = max(label[dd, rr], val)

        return label

    def _unwrap_sample(self, idx):
        """Handle both dict elements and 0-D object arrays safely."""
        raw = self.samples[idx]
        if isinstance(raw, dict):
            return raw
        if isinstance(raw, np.ndarray) and raw.shape == () and raw.dtype == object:
            return raw.item()
        return raw

    def __getitem__(self, idx):
        sample = self._unwrap_sample(idx)
        rdm = np.asarray(sample['range_doppler_map'], dtype=np.float32)   # [D,R]
        targets = sample['target_info']['targets']

        radar_label = self._build_radar_label(rdm, targets)

        ofdm_map = sample['ofdm_map']
        comm_info = sample['comm_info']
        if ofdm_map is None or comm_info is None:
            raise RuntimeError("OFDM map or comm_info missing for TRADITIONAL mode sample.")

        ofdm_map = np.asarray(ofdm_map, dtype=np.float32)  # [N_syms, N_fft]

        tx_ints = np.array(comm_info['tx_ints'], dtype=np.int64)
        num_syms = comm_info['num_data_syms']
        fft_size = comm_info['fft_size']
        mod_order = comm_info['mod_order']

        assert tx_ints.size == num_syms * fft_size, "Mismatch between tx_ints and OFDM grid shape."
        assert ofdm_map.shape == (num_syms, fft_size), "ofdm_map shape mismatch."

        comm_label = tx_ints.reshape(num_syms, fft_size)

        radar_input = torch.from_numpy(rdm).unsqueeze(0)       # [1,D,R]
        radar_target = torch.from_numpy(radar_label).unsqueeze(0)
        comm_input = torch.from_numpy(ofdm_map).unsqueeze(0)   # [1,N_syms,N_fft]
        comm_target = torch.from_numpy(comm_label)             # [N_syms,N_fft]

        meta = {
            'mod_order': mod_order,
            'num_syms': num_syms,
            'fft_size': fft_size,
            'idx': idx
        }

        return radar_input, radar_target, comm_input, comm_target, meta


# ----------------------------------------------------------------------
# Model: CNN + Token-Capped Self-Attention
# ----------------------------------------------------------------------
class ConvBlock(nn.Module):
    def __init__(self, in_ch, out_ch, k=3, s=1, p=1):
        super().__init__()
        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=p)
        self.bn = nn.BatchNorm2d(out_ch)
        self.act = nn.SiLU(inplace=True)

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))


class SelfAttention2D(nn.Module):
    """
    2D self-attention with a cap on the number of tokens.

    If H*W <= max_tokens:
      - run full attention on the HxW grid.

    If H*W > max_tokens:
      - adaptive average-pool down to (H',W') s.t. H'*W' <= max_tokens,
      - run attention on pooled grid,
      - bilinear upsample back to (H,W) and add residual to original x.
    """
    def __init__(self, channels, num_heads=4, dropout=0.1, max_tokens=4096):
        super().__init__()
        self.norm = nn.LayerNorm(channels)
        self.attn = nn.MultiheadAttention(embed_dim=channels,
                                          num_heads=num_heads,
                                          dropout=dropout,
                                          batch_first=False)
        self.dropout = nn.Dropout(dropout)
        self.max_tokens = max_tokens

    def _run_attn(self, x):
        """
        x: [B,C,H,W] with H*W small enough for full attention.
        """
        B, C, H, W = x.shape
        L = H * W
        x_flat = x.view(B, C, L).permute(2, 0, 1)  # [L,B,C]
        x_norm = self.norm(x_flat)
        attn_out, _ = self.attn(x_norm, x_norm, x_norm)
        x_out = x_flat + self.dropout(attn_out)
        x_out = x_out.permute(1, 2, 0).view(B, C, H, W)
        return x_out

    def forward(self, x):
        B, C, H, W = x.shape
        L = H * W

        if L <= self.max_tokens:
            # Full attention at original resolution
            return self._run_attn(x)

        # Token-capped path: pool -> attention -> upsample + residual
        target_tokens = self.max_tokens

        # Maintain aspect ratio roughly
        scale = math.sqrt(target_tokens / float(L))
        H_new = max(1, int(round(H * scale)))
        W_new = max(1, int(round(W * scale)))
        # Clamp in case rounding pushes over max_tokens
        while H_new * W_new > target_tokens:
            if H_new >= W_new:
                H_new = max(1, H_new - 1)
            else:
                W_new = max(1, W_new - 1)

        pooled = F.adaptive_avg_pool2d(x, (H_new, W_new))
        attn_pooled = self._run_attn(pooled)
        attn_ups = F.interpolate(attn_pooled, size=(H, W),
                                 mode="bilinear", align_corners=False)

        # Residual: original features + upsampled attended features
        return x + attn_ups


class RadarBranch(nn.Module):
    def __init__(self, in_ch=1, base_ch=32, num_blocks=3, attn_heads=4, attn_tokens=4096):
        super().__init__()
        ch = base_ch
        layers = [ConvBlock(in_ch, ch)]
        for _ in range(num_blocks - 1):
            layers.append(ConvBlock(ch, ch))
        self.cnn = nn.Sequential(*layers)
        self.attn = SelfAttention2D(ch, num_heads=attn_heads, max_tokens=attn_tokens)
        self.head = nn.Sequential(
            ConvBlock(ch, ch),
            nn.Conv2d(ch, 1, kernel_size=1)  # logits heatmap
        )

    def forward(self, x):
        feat = self.cnn(x)
        feat = self.attn(feat)
        logits = self.head(feat)
        return logits


class CommBranch(nn.Module):
    def __init__(self, in_ch=1, base_ch=32, num_blocks=3,
                 attn_heads=4, max_mod_order=64, attn_tokens=4096):
        super().__init__()
        ch = base_ch
        layers = [ConvBlock(in_ch, ch)]
        for _ in range(num_blocks - 1):
            layers.append(ConvBlock(ch, ch))
        self.cnn = nn.Sequential(*layers)
        self.attn = SelfAttention2D(ch, num_heads=attn_heads, max_tokens=attn_tokens)
        self.head = nn.Sequential(
            ConvBlock(ch, ch),
            nn.Conv2d(ch, max_mod_order, kernel_size=1)  # logits over constellation points
        )
        self.max_mod_order = max_mod_order

    def forward(self, x, mod_order):
        feat = self.cnn(x)
        feat = self.attn(feat)
        logits_full = self.head(feat)  # [B,max_M,H,W]
        return logits_full[:, :mod_order, :, :]  # [B,M,H,W]


class JointRadarCommNet(nn.Module):
    def __init__(self, max_mod_order=64, base_ch=32, num_blocks=3,
                 attn_heads=4, attn_tokens=4096):
        super().__init__()
        self.radar_branch = RadarBranch(in_ch=1, base_ch=base_ch,
                                        num_blocks=num_blocks,
                                        attn_heads=attn_heads,
                                        attn_tokens=attn_tokens)
        self.comm_branch = CommBranch(in_ch=1, base_ch=base_ch,
                                      num_blocks=num_blocks,
                                      attn_heads=attn_heads,
                                      max_mod_order=max_mod_order,
                                      attn_tokens=attn_tokens)

    def forward(self, radar_input, comm_input, mod_order):
        """
        radar_input: [B,1,D,R]
        comm_input:  [B,1,N_syms,N_fft]
        mod_order: int
        """
        radar_logits = self.radar_branch(radar_input)
        comm_logits = self.comm_branch(comm_input, mod_order)
        return radar_logits, comm_logits


# ----------------------------------------------------------------------
# Losses & Training
# ----------------------------------------------------------------------
def compute_losses(radar_logits, radar_target, comm_logits, comm_target, mod_order,
                   radar_pos_weight=4.0, lambda_comm=1.0):
    """
    radar_logits: [B,1,D,R], radar_target: [B,1,D,R]
    comm_logits:  [B,M,N_syms,N_fft], comm_target: [B,N_syms,N_fft]
    """
    # Radar: BCE with positive class weighting (sparse targets)
    pos_weight = torch.tensor([radar_pos_weight], device=radar_logits.device)
    bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
    radar_loss = bce(radar_logits, radar_target)

    # Comm: CrossEntropy per tone
    B, M, H, W = comm_logits.shape
    assert M == mod_order, f"Expected mod_order={mod_order}, got {M}"
    ce = nn.CrossEntropyLoss()
    logits_flat = comm_logits.permute(0, 2, 3, 1).reshape(-1, M)  # [(B*H*W),M]
    labels_flat = comm_target.reshape(-1).long()                  # [(B*H*W)]
    comm_loss = ce(logits_flat, labels_flat)

    total_loss = radar_loss + lambda_comm * comm_loss
    return total_loss, radar_loss, comm_loss


def train_one_epoch(model, loader, optimizer, device, mod_order,
                    grad_clip=1.0, lambda_comm=1.0):
    model.train()
    total_loss = total_radar = total_comm = 0.0
    n_samples = 0

    for batch in loader:
        radar_in, radar_tgt, comm_in, comm_tgt, meta = batch
        radar_in = radar_in.to(device)
        radar_tgt = radar_tgt.to(device)
        comm_in = comm_in.to(device)
        comm_tgt = comm_tgt.to(device)
        bsz = radar_in.size(0)

        optimizer.zero_grad()
        radar_logits, comm_logits = model(radar_in, comm_in, mod_order=mod_order)
        loss, l_radar, l_comm = compute_losses(radar_logits, radar_tgt,
                                               comm_logits, comm_tgt,
                                               mod_order=mod_order,
                                               lambda_comm=lambda_comm)
        loss.backward()
        if grad_clip is not None:
            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)
        optimizer.step()

        total_loss += loss.item() * bsz
        total_radar += l_radar.item() * bsz
        total_comm += l_comm.item() * bsz
        n_samples += bsz

    return total_loss / n_samples, total_radar / n_samples, total_comm / n_samples


@torch.no_grad()
def evaluate_ser(model, loader, device, mod_order):
    """Compute average symbol error rate across loader (proxy for BER)."""
    model.eval()
    total_ser = 0.0
    total_samples = 0

    for batch in loader:
        radar_in, radar_tgt, comm_in, comm_tgt, meta = batch
        radar_in = radar_in.to(device)
        comm_in = comm_in.to(device)
        comm_tgt = comm_tgt.to(device)

        B = radar_in.size(0)
        _, comm_logits = model(radar_in, comm_in, mod_order=mod_order)
        pred = comm_logits.argmax(dim=1)  # [B,H,W]
        errors = (pred != comm_tgt).sum().item()
        ser = errors / comm_tgt.numel()
        total_ser += ser * B
        total_samples += B

    return total_ser / max(total_samples, 1)


# ----------------------------------------------------------------------
# Radar heatmap post-processing (DL -> detection list)
# ----------------------------------------------------------------------
def postprocess_radar_heatmap(probs, r_axis, v_axis, cfg,
                              prob_thresh=0.5):
    """
    probs: [D,R] probability map from sigmoid.
    Returns detections list similar to CFAR outputs:
      [{'range_m','velocity_mps','range_idx','doppler_idx','score'}, ...]
    """
    params = cfg.get('cfar_params', {})
    nms_kernel = params.get('nms_kernel_size', 5)
    min_r = params.get('min_range_m', 0.0)
    min_v = params.get('min_speed_mps', 0.0)
    notch_k = params.get('notch_doppler_bins', 0)
    max_peaks = params.get('max_peaks', None)

    # NMS on probability map
    local_max = maximum_filter(probs, size=nms_kernel)
    detections_mask = (probs >= prob_thresh) & (probs == local_max)

    idxs = np.argwhere(detections_mask)
    center = len(v_axis) // 2
    candidates = []

    for d_idx, r_idx in idxs:
        if d_idx >= len(v_axis) or r_idx >= len(r_axis):
            continue
        range_m = r_axis[r_idx]
        vel_mps = v_axis[d_idx]

        # Similar filtering as CFAR
        if range_m < min_r or abs(vel_mps) < min_v:
            continue
        if notch_k > 0 and abs(d_idx - center) <= notch_k:
            continue

        candidates.append({
            'range_m': float(range_m),
            'velocity_mps': float(vel_mps),
            'range_idx': int(r_idx),
            'doppler_idx': int(d_idx),
            'score': float(probs[d_idx, r_idx]),
        })

    # Score-based peak limiting
    if max_peaks is not None:
        candidates.sort(key=lambda x: x['score'], reverse=True)
        candidates = candidates[:max_peaks]

    # Coarser NMS on cell blocks (connected component pruning)
    pruned = []
    taken = set()
    neigh = params.get('nms_kernel_size', 5)
    for det in candidates:
        key = (det['doppler_idx'] // neigh, det['range_idx'] // neigh)
        if key in taken:
            continue
        taken.add(key)
        pruned.append(det)

    return pruned


# ----------------------------------------------------------------------
# Radar metrics (same logic as your earlier _evaluate_metrics)
# ----------------------------------------------------------------------
def evaluate_radar_metrics(targets, detections, match_dist_thresh=3.0):
    tp = 0
    range_errors = []
    vel_errors = []
    unmatched_targets = list(targets)
    unmatched_detections = list(detections)
    matched_pairs = []

    for t in list(unmatched_targets):
        best_dist = float('inf')
        best_idx = -1
        for i, d in enumerate(unmatched_detections):
            d_r = t['range'] - d['range_m']
            d_v = t['velocity'] - d['velocity_mps']
            dist = math.hypot(d_r, d_v)
            if dist < match_dist_thresh and dist < best_dist:
                best_dist = dist
                best_idx = i

        if best_idx != -1:
            tp += 1
            det = unmatched_detections.pop(best_idx)
            unmatched_targets.remove(t)
            range_errors.append(abs(t['range'] - det['range_m']))
            vel_errors.append(abs(t['velocity'] - det['velocity_mps']))
            matched_pairs.append((t, det))

    fp = len(unmatched_detections)
    fn = len(unmatched_targets)

    metrics = {
        'tp': tp,
        'fp': fp,
        'fn': fn,
        'mean_range_error': float(np.mean(range_errors) if range_errors else 0.0),
        'mean_velocity_error': float(np.mean(vel_errors) if vel_errors else 0.0),
        'total_targets': len(targets),
    }
    return metrics, matched_pairs, unmatched_targets, unmatched_detections


# ----------------------------------------------------------------------
# Communication visualization helpers
# ----------------------------------------------------------------------
def generate_qam_constellation(mod_order):
    if mod_order == 4:
        pts = np.array([1+1j, 1-1j, -1+1j, -1-1j]) / np.sqrt(2)
    elif mod_order == 16:
        x = np.arange(-3, 4, 2)
        X, Y = np.meshgrid(x, x)
        pts = (X + 1j * Y).flatten() / np.sqrt(10)
    elif mod_order == 64:
        x = np.arange(-7, 8, 2)
        X, Y = np.meshgrid(x, x)
        pts = (X + 1j * Y).flatten() / np.sqrt(42)
    else:
        raise ValueError(f"Unsupported mod_order {mod_order}")
    return pts


def plot_eye_diagram(symbols, sps=2, save_path=None):
    """
    Approximate eye diagram using real part of equalized Rx symbols.
    Not a full oversampled eye, but gives a quick visual sanity check.
    """
    x = np.real(symbols)
    seq = np.repeat(x, sps)  # simple upsample

    seg_len = 4 * sps   # 4-symbol window
    n_seg = len(seq) // seg_len

    fig, ax = plt.subplots(figsize=(6, 4))
    for i in range(n_seg):
        seg = seq[i * seg_len:(i + 1) * seg_len]
        t = np.arange(len(seg)) / sps
        ax.plot(t, seg, alpha=0.2)

    ax.set_xlabel("Symbol time")
    ax.set_ylabel("Amplitude (I)")
    ax.set_title("Eye Diagram (approx)")
    ax.grid(True, alpha=0.3)
    plt.tight_layout()

    if save_path is not None:
        plt.savefig(save_path, dpi=150)
        plt.close(fig)
    else:
        return fig, ax


def plot_comm_results(comm_info, pred_ints, mod_order, dl_ser, save_prefix):
    """
    Save:
      - constellation comparison (Tx, Rx, DL demap)
      - approximate eye diagram
      - overlay BER/SER stats
    """
    tx_syms = np.array(comm_info['tx_symbols'])
    rx_syms = np.array(comm_info['rx_symbols'])
    const_pts = generate_qam_constellation(mod_order)
    tx_ints = np.array(comm_info['tx_ints'], dtype=int)
    tx_pts = const_pts[tx_ints]
    pred_pts = const_pts[pred_ints.astype(int)]
    baseline_ber = comm_info.get('ber', 0.0)

    # Constellation + eye
    fig, ax = plt.subplots(1, 2, figsize=(12, 5))

    # Constellation
    ax0 = ax[0]
    idx = np.arange(len(tx_syms))
    if len(idx) > 2000:
        sel = np.random.choice(idx, 2000, replace=False)
    else:
        sel = idx

    ax0.scatter(np.real(rx_syms[sel]), np.imag(rx_syms[sel]),
                s=8, alpha=0.4, label="Rx (ZF+LS)")
    ax0.scatter(np.real(tx_syms[sel]), np.imag(tx_syms[sel]),
                s=12, alpha=0.6, marker='x', label="Tx")
    ax0.scatter(np.real(pred_pts[sel]), np.imag(pred_pts[sel]),
                s=10, alpha=0.5, marker='+', label="DL Demap")

    ax0.set_title(f"{mod_order}-QAM Constellation")
    ax0.set_xlabel("I")
    ax0.set_ylabel("Q")
    ax0.grid(True, alpha=0.3)
    ax0.legend(fontsize=8)
    ax0.set_aspect('equal')

    # Eye: render separately then embed as image
    eye_path = save_prefix + "_eye.png"
    plot_eye_diagram(rx_syms, sps=2, save_path=eye_path)
    img = plt.imread(eye_path)

    ax1 = ax[1]
    ax1.imshow(img)
    ax1.axis('off')
    text = (
        f"Baseline BER: {baseline_ber:.3e}\n"
        f"DL SER≈BER: {dl_ser:.3e}\n"
        f"#Symbols: {len(tx_ints)}"
    )
    props = dict(boxstyle='round', facecolor='white', alpha=0.8)
    ax1.text(0.02, 0.98, text, transform=ax1.transAxes,
             fontsize=9, verticalalignment='top',
             bbox=props, family='monospace')

    plt.tight_layout()
    const_path = save_prefix + "_constellation_eye.png"
    plt.savefig(const_path, dpi=150)
    plt.close(fig)


# ----------------------------------------------------------------------
# Radar visualization (2D & 3D)
# ----------------------------------------------------------------------
def plot_radar_2d_comparison(rdm_db, r_axis, v_axis,
                             targets, cfar_dets, dl_dets,
                             metrics_cfar, metrics_dl,
                             save_path):
    fig, ax = plt.subplots(figsize=(12, 8))

    dr = r_axis[1] - r_axis[0] if len(r_axis) > 1 else 1.0
    dv = v_axis[1] - v_axis[0] if len(v_axis) > 1 else 1.0
    extent = [r_axis[0] - dr/2, r_axis[-1] + dr/2,
              v_axis[0] - dv/2, v_axis[-1] + dv/2]

    im = ax.imshow(rdm_db, extent=extent, origin='lower',
                   cmap='viridis', aspect='auto')
    plt.colorbar(im, ax=ax, label="Magnitude (dB)")

    ax.set_xlabel("Range (m)")
    ax.set_ylabel("Velocity (m/s)")
    ax.set_title("Range-Doppler Map: CFAR vs Deep Model")

    # Ground truth
    for t in targets:
        ax.scatter(t['range'], t['velocity'], facecolors='none', edgecolors='lime',
                   s=150, linewidth=2, label='GT')

    # CFAR detections
    for d in cfar_dets:
        ax.scatter(d['range_m'], d['velocity_mps'], marker='x', color='cyan',
                   s=80, linewidth=2, label='CFAR')

    # DL detections
    for d in dl_dets:
        ax.scatter(d['range_m'], d['velocity_mps'], marker='+', color='red',
                   s=80, linewidth=2, label='DL')

    # Deduplicate legend entries
    handles, labels = ax.get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    ax.legend(by_label.values(), by_label.keys(), loc='upper right', fontsize=8)

    text = (
        "CFAR Metrics:\n"
        f"  TP={metrics_cfar['tp']} FP={metrics_cfar['fp']} FN={metrics_cfar['fn']}\n"
        f"  dR={metrics_cfar['mean_range_error']:.2f} m, dV={metrics_cfar['mean_velocity_error']:.2f} m/s\n"
        "\nDL Metrics:\n"
        f"  TP={metrics_dl['tp']} FP={metrics_dl['fp']} FN={metrics_dl['fn']}\n"
        f"  dR={metrics_dl['mean_range_error']:.2f} m, dV={metrics_dl['mean_velocity_error']:.2f} m/s\n"
    )
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.6)
    ax.text(0.02, 0.98, text, transform=ax.transAxes,
            fontsize=9, verticalalignment='top', bbox=props, family='monospace')

    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    plt.close(fig)


def plot_radar_3d(rdm_db, r_axis, v_axis, targets, detections, save_path):
    """
    3D RD map with DL detections. If AIRadarLib is available, use it;
    otherwise fallback to Matplotlib 3D surface.
    """
    if VISUALIZATION_AVAILABLE:
        range_res = r_axis[1] - r_axis[0] if len(r_axis) > 1 else 1.0
        vel_res = v_axis[1] - v_axis[0] if len(v_axis) > 1 else 1.0

        converted_targets = []
        for t in targets:
            ct = t.copy()
            ct['distance'] = t['range']
            converted_targets.append(ct)

        cleaned_dets = []
        for d in detections:
            d2 = d.copy()
            d2['range_idx'] = int(d2.get('range_idx', 0))
            d2['doppler_idx'] = int(d2.get('doppler_idx', 0))
            cleaned_dets.append(d2)

        plot_3d_range_doppler_map_with_ground_truth(
            rd_map=rdm_db,
            targets=converted_targets,
            range_resolution=range_res,
            velocity_resolution=vel_res,
            num_range_bins=rdm_db.shape[1],
            num_doppler_bins=rdm_db.shape[0],
            save_path=save_path,
            apply_doppler_centering=True,
            detections=cleaned_dets,
            view_range_limits=(r_axis[0], r_axis[-1]),
            view_velocity_limits=(v_axis[0], v_axis[-1]),
            is_db=True,
            stride=4
        )
    else:
        R_grid, D_grid = np.meshgrid(r_axis, v_axis)
        fig = plt.figure(figsize=(10, 7))
        ax = fig.add_subplot(111, projection='3d')
        surf = ax.plot_surface(R_grid, D_grid, rdm_db, cmap='viridis')
        ax.set_xlabel("Range (m)")
        ax.set_ylabel("Velocity (m/s)")
        ax.set_zlabel("Mag (dB)")
        fig.colorbar(surf, shrink=0.5, aspect=10)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150)
        plt.close(fig)


# ----------------------------------------------------------------------
# Full evaluation: radar & comm + visualizations
# ----------------------------------------------------------------------
@torch.no_grad()
def run_full_evaluation(model, dataset, cfg, device, out_dir,
                        mod_order, max_vis=10, prob_thresh=0.5):
    os.makedirs(out_dir, exist_ok=True)

    total_cfar = {'tp': 0, 'fp': 0, 'fn': 0, 'range_err': [], 'vel_err': [], 'targets': 0}
    total_dl = {'tp': 0, 'fp': 0, 'fn': 0, 'range_err': [], 'vel_err': [], 'targets': 0}
    baseline_bers = []
    dl_sers = []

    for idx in range(len(dataset)):
        sample_raw = dataset._unwrap_sample(idx)
        radar_in, radar_tgt, comm_in, comm_tgt, meta = dataset[idx]

        rdm = np.asarray(sample_raw['range_doppler_map'], dtype=np.float32)
        targets = sample_raw['target_info']['targets']
        cfar_dets = sample_raw['cfar_detections']
        comm_info = sample_raw['comm_info']

        r_axis, v_axis, _, _ = dataset._compute_axes(rdm)

        # Classical CFAR metrics
        metrics_cfar, _, _, _ = evaluate_radar_metrics(targets, cfar_dets)
        total_cfar['tp'] += metrics_cfar['tp']
        total_cfar['fp'] += metrics_cfar['fp']
        total_cfar['fn'] += metrics_cfar['fn']
        total_cfar['targets'] += metrics_cfar['total_targets']
        total_cfar['range_err'].append(metrics_cfar['mean_range_error'])
        total_cfar['vel_err'].append(metrics_cfar['mean_velocity_error'])

        # Deep model predictions
        model.eval()
        radar_in_b = radar_in.unsqueeze(0).to(device)
        comm_in_b = comm_in.unsqueeze(0).to(device)
        comm_tgt_b = comm_tgt.unsqueeze(0).to(device)

        radar_logits, comm_logits = model(radar_in_b, comm_in_b, mod_order=mod_order)
        radar_probs = torch.sigmoid(radar_logits)[0, 0].cpu().numpy()
        dl_dets = postprocess_radar_heatmap(radar_probs, r_axis, v_axis, cfg,
                                            prob_thresh=prob_thresh)

        metrics_dl, _, _, _ = evaluate_radar_metrics(targets, dl_dets)
        total_dl['tp'] += metrics_dl['tp']
        total_dl['fp'] += metrics_dl['fp']
        total_dl['fn'] += metrics_dl['fn']
        total_dl['targets'] += metrics_dl['total_targets']
        total_dl['range_err'].append(metrics_dl['mean_range_error'])
        total_dl['vel_err'].append(metrics_dl['mean_velocity_error'])

        # Comm metrics
        baseline_ber = comm_info.get('ber', 0.0)
        baseline_bers.append(baseline_ber)

        pred_ints = comm_logits.argmax(dim=1)[0].cpu().numpy().reshape(-1)
        gt_ints = comm_tgt_b.cpu().numpy().reshape(-1)
        ser = (pred_ints != gt_ints).mean()
        dl_sers.append(ser)

        # Visualizations for first few samples
        if idx < max_vis:
            prefix = os.path.join(out_dir, f"sample_{idx:03d}")
            rdm_norm = rdm - np.max(rdm)

            plot_radar_2d_comparison(rdm_norm, r_axis, v_axis,
                                     targets, cfar_dets, dl_dets,
                                     metrics_cfar, metrics_dl,
                                     save_path=prefix + "_radar_2d.png")

            plot_radar_3d(rdm_norm, r_axis, v_axis, targets, dl_dets,
                          save_path=prefix + "_radar_3d_dl.png")

            plot_comm_results(comm_info, pred_ints, mod_order, ser,
                              save_prefix=prefix + "_comm")

    # Aggregate metrics
    def agg(total):
        tp = total['tp']
        fp = total['fp']
        fn = total['fn']
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
        mean_range = float(np.mean(total['range_err'])) if total['range_err'] else 0.0
        mean_vel = float(np.mean(total['vel_err'])) if total['vel_err'] else 0.0
        return precision, recall, f1, mean_range, mean_vel

    p_cfar, r_cfar, f1_cfar, mr_cfar, mv_cfar = agg(total_cfar)
    p_dl, r_dl, f1_dl, mr_dl, mv_dl = agg(total_dl)
    mean_baseline_ber = float(np.mean(baseline_bers)) if baseline_bers else 0.0
    mean_dl_ser = float(np.mean(dl_sers)) if dl_sers else 0.0

    summary = []
    summary.append("=== Radar Metrics (Classical CFAR) ===")
    summary.append(f"Targets: {total_cfar['targets']}")
    summary.append(f"TP={total_cfar['tp']} FP={total_cfar['fp']} FN={total_cfar['fn']}")
    summary.append(f"Precision={p_cfar:.4f} Recall={r_cfar:.4f} F1={f1_cfar:.4f}")
    summary.append(f"Mean Range Error={mr_cfar:.3f} m")
    summary.append(f"Mean Velocity Error={mv_cfar:.3f} m/s")
    summary.append("")
    summary.append("=== Radar Metrics (Deep Model) ===")
    summary.append(f"Targets: {total_dl['targets']}")
    summary.append(f"TP={total_dl['tp']} FP={total_dl['fp']} FN={total_dl['fn']}")
    summary.append(f"Precision={p_dl:.4f} Recall={r_dl:.4f} F1={f1_dl:.4f}")
    summary.append(f"Mean Range Error={mr_dl:.3f} m")
    summary.append(f"Mean Velocity Error={mv_dl:.3f} m/s")
    summary.append("")
    summary.append("=== Communication Metrics ===")
    summary.append(f"Baseline Mean BER={mean_baseline_ber:.5e}")
    summary.append(f"Deep Model SER≈BER={mean_dl_ser:.5e}")

    txt = "\n".join(summary)
    print(txt)

    with open(os.path.join(out_dir, "evaluation_summary.txt"), "w") as f:
        f.write(txt)


# ----------------------------------------------------------------------
# Utilities & main
# ----------------------------------------------------------------------
def set_seed(seed=42):
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", type=str, choices=["train", "evaluate", "inference"],
                        default="train",
                        help="train: fit model; evaluate: full eval; inference: single-sample viz")
    parser.add_argument("--config_name", type=str, default="CN0566_TRADITIONAL",
                        choices=list(RADAR_COMM_CONFIGS.keys()))
    parser.add_argument("--data_root", type=str,
                        default="data/AIradar_comm_dataset_g1b")
    parser.add_argument("--batch_size", type=int, default=4)
    parser.add_argument("--epochs", type=int, default=20)
    parser.add_argument("--lr", type=float, default=1e-3)
    parser.add_argument("--lambda_comm", type=float, default=1.0)
    parser.add_argument("--device", type=str,
                        default="cuda" if torch.cuda.is_available() else "cpu")
    parser.add_argument("--out_dir", type=str, default="data/AIradar_comm_model_g1")
    parser.add_argument("--ckpt", type=str, default=None,
                        help="Checkpoint path for evaluate/inference modes")
    parser.add_argument("--sample_idx", type=int, default=0,
                        help="For inference mode: which sample index to visualize.")
    parser.add_argument("--prob_thresh", type=float, default=0.5,
                        help="DL radar detection probability threshold.")
    parser.add_argument("--attn_tokens", type=int, default=4096,
                        help="Max tokens for 2D attention (controls memory).")
    args = parser.parse_args()

    set_seed(42)

    cfg = RADAR_COMM_CONFIGS[args.config_name]
    assert cfg['mode'] == 'TRADITIONAL', "Use a TRADITIONAL config for this script."

    npy_path = os.path.join(args.data_root, args.config_name, "joint_dump.npy")
    if not os.path.exists(npy_path):
        raise FileNotFoundError(f"joint_dump.npy not found at {npy_path}")

    dataset = JointRadarCommDataset(npy_path, args.config_name)
    device = torch.device(args.device)
    mod_order = cfg['mod_order']

    model = JointRadarCommNet(max_mod_order=64, base_ch=48,
                              num_blocks=4, attn_heads=4,
                              attn_tokens=args.attn_tokens).to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=1e-4)

    # -------------------------- TRAIN MODE --------------------------
    if args.mode == "train":
        n_total = len(dataset)
        n_train = int(0.8 * n_total)
        n_val = n_total - n_train
        train_ds, val_ds = torch.utils.data.random_split(dataset, [n_train, n_val])

        train_loader = DataLoader(train_ds, batch_size=args.batch_size,
                                  shuffle=True, num_workers=4, pin_memory=True)
        val_loader = DataLoader(val_ds, batch_size=args.batch_size,
                                shuffle=False, num_workers=4, pin_memory=True)

        best_ser = float("inf")
        os.makedirs(args.out_dir, exist_ok=True)

        for epoch in range(1, args.epochs + 1):
            train_loss, train_radar, train_comm = train_one_epoch(
                model, train_loader, optimizer, device,
                mod_order=mod_order, lambda_comm=args.lambda_comm
            )
            val_ser = evaluate_ser(model, val_loader, device, mod_order)

            print(f"[Epoch {epoch:02d}] "
                  f"TrainLoss={train_loss:.4f} (Radar={train_radar:.4f}, Comm={train_comm:.4f}) "
                  f"| Val SER≈BER={val_ser:.4e}")

            if val_ser < best_ser:
                best_ser = val_ser
                ckpt_path = os.path.join(args.out_dir,
                                         f"joint_net_{args.config_name}_best.pt")
                torch.save({
                    "model_state": model.state_dict(),
                    "config_name": args.config_name,
                    "mod_order": mod_order
                }, ckpt_path)
                print(f"  -> New best model saved to {ckpt_path}")

        # After training, evaluate on full dataset + save visualizations
        eval_dir = os.path.join(args.out_dir, "train_eval")
        run_full_evaluation(model, dataset, cfg, device, eval_dir,
                            mod_order=mod_order, max_vis=10,
                            prob_thresh=args.prob_thresh)

    # ------------------------ EVALUATE MODE -------------------------
    elif args.mode == "evaluate":
        assert args.ckpt is not None, "Provide --ckpt for evaluate mode."
        ckpt = torch.load(args.ckpt, map_location=device)
        model.load_state_dict(ckpt["model_state"])
        model.to(device)

        eval_dir = os.path.join(args.out_dir, "evaluate")
        run_full_evaluation(model, dataset, cfg, device, eval_dir,
                            mod_order=mod_order, max_vis=10,
                            prob_thresh=args.prob_thresh)

    # ------------------------ INFERENCE MODE ------------------------
    elif args.mode == "inference":
        assert args.ckpt is not None, "Provide --ckpt for inference mode."
        ckpt = torch.load(args.ckpt, map_location=device)
        model.load_state_dict(ckpt["model_state"])
        model.to(device)
        model.eval()

        idx = args.sample_idx
        if idx < 0 or idx >= len(dataset):
            raise IndexError(f"sample_idx {idx} out of range [0, {len(dataset)-1}]")

        radar_in, radar_tgt, comm_in, comm_tgt, meta = dataset[idx]
        sample_raw = dataset._unwrap_sample(idx)

        rdm = np.asarray(sample_raw['range_doppler_map'], dtype=np.float32)
        targets = sample_raw['target_info']['targets']
        cfar_dets = sample_raw['cfar_detections']
        comm_info = sample_raw['comm_info']
        r_axis, v_axis, _, _ = dataset._compute_axes(rdm)

        out_dir = os.path.join(args.out_dir, f"inference_sample_{idx:03d}")
        os.makedirs(out_dir, exist_ok=True)

        radar_in_b = radar_in.unsqueeze(0).to(device)
        comm_in_b = comm_in.unsqueeze(0).to(device)
        comm_tgt_b = comm_tgt.unsqueeze(0).to(device)

        radar_logits, comm_logits = model(radar_in_b, comm_in_b, mod_order=mod_order)
        radar_probs = torch.sigmoid(radar_logits)[0, 0].cpu().numpy()
        dl_dets = postprocess_radar_heatmap(radar_probs, r_axis, v_axis, cfg,
                                            prob_thresh=args.prob_thresh)

        metrics_cfar, _, _, _ = evaluate_radar_metrics(targets, cfar_dets)
        metrics_dl, _, _, _ = evaluate_radar_metrics(targets, dl_dets)

        rdm_norm = rdm - np.max(rdm)
        prefix = os.path.join(out_dir, f"sample_{idx:03d}")

        plot_radar_2d_comparison(rdm_norm, r_axis, v_axis,
                                 targets, cfar_dets, dl_dets,
                                 metrics_cfar, metrics_dl,
                                 save_path=prefix + "_radar_2d.png")

        plot_radar_3d(rdm_norm, r_axis, v_axis, targets, dl_dets,
                      save_path=prefix + "_radar_3d_dl.png")

        pred_ints = comm_logits.argmax(dim=1)[0].cpu().numpy().reshape(-1)
        gt_ints = comm_tgt_b.cpu().numpy().reshape(-1)
        ser = (pred_ints != gt_ints).mean()

        plot_comm_results(comm_info, pred_ints, mod_order, ser,
                          save_prefix=prefix + "_comm")

        with open(os.path.join(out_dir, "inference_summary.txt"), "w") as f:
            f.write("Inference summary\n")
            f.write("CFAR metrics:\n")
            f.write(str(metrics_cfar) + "\n")
            f.write("Deep model metrics:\n")
            f.write(str(metrics_dl) + "\n")
            f.write(f"CFAR baseline BER={comm_info.get('ber', 0.0):.5e}\n")
            f.write(f"Deep model SER≈BER={ser:.5e}\n")


if __name__ == "__main__":
    main()